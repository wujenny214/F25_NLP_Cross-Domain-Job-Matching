{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461cc621",
   "metadata": {},
   "source": [
    "# Job Description Data Cleaning Pipeline\n",
    "\n",
    "## 1. Data Exploration and Initial Load\n",
    "Load and explore the raw job description dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f1c724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries for data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11f3dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw dataset\n",
    "jd_df = pd.read_csv(\"../0_raw_dataset/job_description.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c8ef48",
   "metadata": {},
   "source": [
    "## 2. Clean Job Location Data\n",
    "### 2.1 Remove Invalid Location Entries\n",
    "Remove entries starting with \"Contact\" that contain no useful location information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d370cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_delete = jd_df[\"location\"].astype(str).str.startswith(\"Contact\")\n",
    "jd_df = jd_df[~location_delete]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60753d",
   "metadata": {},
   "source": [
    "### 2.2 Filter Location by Length\n",
    "Keep only locations between 5 and 50 characters to remove incomplete or malformed entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "544a50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jd_df[jd_df[\"location\"].str.len() > 50][[\"job_title\", \"location\"]]\n",
    "jd_df = jd_df[jd_df[\"location\"].str.len().between(5, 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e6a410",
   "metadata": {},
   "source": [
    "### 2.3 Extract Standardized Location Format\n",
    "Use regex to extract \"City, STATE\" format from location strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e337398",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_df = jd_df.copy()\n",
    "\n",
    "\n",
    "def clean_location(text):\n",
    "    text = str(text).strip()\n",
    "    match = re.search(r\"[A-Za-z\\s]+,\\s*[A-Z]{2}$\", text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "\n",
    "jd_df[\"location_cleaned\"] = jd_df[\"location\"].apply(clean_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "620fb2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_df = jd_df.dropna(subset=[\"location_cleaned\"]).copy()\n",
    "keep_columns = [\"job_title\", \"job_description\", \"location_cleaned\"]\n",
    "jd_df = jd_df[keep_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9408e5c5",
   "metadata": {},
   "source": [
    "## 3. Clean Job Title Data\n",
    "### 3.1 Extract Job Title from Pattern\n",
    "Extract the actual job title before \"Job in [Location]\" pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eae8b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_df[\"job_title_cleaned\"] = jd_df[\"job_title\"].str.split(\" Job in \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bbd987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_title(title):\n",
    "    if pd.isna(title):\n",
    "        return None\n",
    "\n",
    "    title = str(title).strip()\n",
    "\n",
    "    # Remove \"Job in {location}\" pattern\n",
    "    title = re.split(r\"\\s+Job in\\s+\", title, flags=re.IGNORECASE)[0]\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    title = re.sub(r\"\\s+\", \" \", title)\n",
    "\n",
    "    # Remove trailing dashes or slashes\n",
    "    title = re.sub(r\"[-/\\s]+$\", \"\", title)\n",
    "\n",
    "    # Standardize case (optional - Title Case)\n",
    "    # title = title.title()\n",
    "\n",
    "    return title.strip()\n",
    "\n",
    "\n",
    "jd_df[\"job_title_cleaned\"] = jd_df[\"job_title\"].apply(clean_job_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21626c79",
   "metadata": {},
   "source": [
    "### 3.2 Remove Missing and Incomplete Titles\n",
    "Drop rows with missing titles or titles shorter than 3 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f4b26d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles without 'Job in' pattern: 785\n",
      "Titles longer than 100 chars: 4\n"
     ]
    }
   ],
   "source": [
    "# Check for titles without \"Job in\" pattern\n",
    "no_pattern = jd_df[~jd_df[\"job_title\"].str.contains(\"Job in\", na=False)]\n",
    "print(f\"Titles without 'Job in' pattern: {len(no_pattern)}\")\n",
    "\n",
    "# Check for very long titles (might indicate messy data)\n",
    "long_titles = jd_df[jd_df[\"job_title_cleaned\"].str.len() > 100]\n",
    "print(f\"Titles longer than 100 chars: {len(long_titles)}\")\n",
    "\n",
    "# Remove rows with missing titles\n",
    "jd_df = jd_df.dropna(subset=[\"job_title_cleaned\"])\n",
    "\n",
    "# Remove very short titles (likely incomplete)\n",
    "jd_df = jd_df[jd_df[\"job_title_cleaned\"].str.len() >= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb30e4",
   "metadata": {},
   "source": [
    "### 3.3 Standardize Similar Job Titles\n",
    "Map variations of job titles to standardized forms (e.g., \"Software Developer\" → \"Software Engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55ae61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map similar titles together\n",
    "title_mapping = {\n",
    "    \"Software Engineer\": [\"software developer\", \"programmer\", \"dev engineer\"],\n",
    "    \"Machine Learning Engineer\": [\"ml engineer\", \"machine learning\"],\n",
    "    \"Project Manager\": [\"program manager\"],\n",
    "    \"Data Analyst\": [\"data analyst\"],\n",
    "    \"Resident Nurse\": [\"registered nurse\"]}\n",
    "\n",
    "\n",
    "def standardize_title(title):\n",
    "    title_lower = title.lower()\n",
    "    for standard, variations in title_mapping.items():\n",
    "        if any(var in title_lower for var in variations + [standard]):\n",
    "            return standard\n",
    "    return title\n",
    "\n",
    "\n",
    "jd_df[\"job_title_standardized\"] = jd_df[\"job_title_cleaned\"].apply(standardize_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509938b",
   "metadata": {},
   "source": [
    "### 3.4 Remove Invalid Job Descriptions\n",
    "Filter out job descriptions containing specific chaotic patterns or spam content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8c7f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if job_description contains the phrase\n",
    "pattern = (\n",
    "    r\"Please apply only if you are qualified\\.|\"\n",
    "    r\"\\$K-\\$K RESTAURANT MANAGER DALLAS! \\$K-\\$K KITCHEN MANAGER ARLINGTON! NEW STORES ACROSS DFW!\"\n",
    ")\n",
    "contains_phrase = jd_df[\"job_description\"].str.contains(\n",
    "    pattern,\n",
    "    case=False,  # case-insensitive\n",
    "    na=False,  # treat NaN as False\n",
    "    regex=True,\n",
    ")\n",
    "\n",
    "# Remove those rows\n",
    "jd_df = jd_df[~contains_phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c28ad26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the unneeded title columns using the correct argument\n",
    "jd_df = jd_df.drop(columns=[\"job_title\", \"job_title_cleaned\"])\n",
    "# rename the standardized title column to 'job_title'\n",
    "jd_df.rename(columns={\"job_title_standardized\": \"job_title\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f16bae",
   "metadata": {},
   "source": [
    "## 4. Clean Job Description Content\n",
    "\n",
    "### 4.1 Remove Invalid Descriptions\n",
    "Filter out descriptions with placeholder text or spam patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a87d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jd_df.copy()\n",
    "\n",
    "df = df[df[\"job_description\"] != \"Please apply only if you are qualified.\"]\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd800b6",
   "metadata": {},
   "source": [
    "### 4.2 Remove Duplicate Job Descriptions\n",
    "Drop rows with duplicate job descriptions while preserving unique entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e607a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many duplicate value\n",
    "dupes = df[df[\"job_description\"].duplicated(keep=False)]\n",
    "same_rows = dupes.groupby(\"job_description\").filter(\n",
    "    lambda g: g.drop(columns=[\"job_description\"]).nunique().sum() == 0\n",
    ")\n",
    "\n",
    "# print(f\"Same job description but different companies, locations, etc., after checking: {len(same_rows)}\")\n",
    "\n",
    "# drop them\n",
    "duplicates = df[\"job_description\"].value_counts()\n",
    "num_duplicate_rows = duplicates[duplicates > 1].sum()\n",
    "# print(\"Total number of duplicate job_description lines:\", num_duplicate_rows)\n",
    "# number not too much, drop them\n",
    "df = df[~df[\"job_description\"].duplicated(keep=False)]\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2ec31",
   "metadata": {},
   "source": [
    "### 4.3 Extract Key Sections: Duties, Requirements, and Education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959bfb40",
   "metadata": {},
   "source": [
    "#### 4.3.1 Pattern Analysis\n",
    "Analyze keyword patterns to identify what percentage of jobs contain each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "762a4837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_76352/1567829725.py:30: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  duties_mask = df[\"job_description\"].str.contains(duties_pattern, case=False, na=False)\n",
      "/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_76352/1567829725.py:71: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  req_mask = df[\"job_description\"].str.contains(req_pattern, case=False, na=False)\n",
      "/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_76352/1567829725.py:84: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  edu_mask = df[\"job_description\"].str.contains(edu_pattern, case=False, na=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 5283\n",
      "Both (Duties+Requirements): 3145 (59.53%)\n",
      "All three present: 2537 (48.02%)\n"
     ]
    }
   ],
   "source": [
    "# check key features in job description only using keywords\n",
    "\n",
    "# === Responsibilities / Duties  ===\n",
    "duties_pattern = (\n",
    "    r\"(?i)\\b(\"\n",
    "    r\"responsibilit(?:y|ies)|\"\n",
    "    r\"duties|\"\n",
    "    r\"tasks|\"\n",
    "    r\"key responsibilities|\"\n",
    "    r\"primary responsibilities|\"\n",
    "    r\"main duties|\"\n",
    "    r\"essential duties|\"\n",
    "    r\"job duties|\"\n",
    "    r\"core responsibilities|\"\n",
    "    r\"what you['’]ll do|\"\n",
    "    r\"what you will do|\"\n",
    "    r\"your role|\"\n",
    "    r\"role overview|\"\n",
    "    r\"day[- ]to[- ]day|\"\n",
    "    r\"main responsibilities|\"\n",
    "    r\"responsibilities|\"\n",
    "    r\"key deliverables|\"\n",
    "    r\"accountabilities|\"\n",
    "    r\"scope of work|\"\n",
    "    r\"what this role does\"\n",
    "    r\")\\b\"\n",
    ")\n",
    "\n",
    "\n",
    "duties_mask = df[\"job_description\"].str.contains(duties_pattern, case=False, na=False)\n",
    "\n",
    "\n",
    "# === Requirements / Qualifications ===\n",
    "req_pattern = (\n",
    "    r\"(?i)\\b(\"\n",
    "    r\"requirements?|\"\n",
    "    r\"qualifications?|\"\n",
    "    r\"skills and experience|\"\n",
    "    r\"required skills?|\"\n",
    "    r\"preferred skills?|\"\n",
    "    r\"experience required|\"\n",
    "    r\"experience and education|\"\n",
    "    r\"knowledge, skills|\"\n",
    "    r\"competencies?|\"\n",
    "    r\"core competencies?|\"\n",
    "    r\"what you['’]ll need|\"\n",
    "    r\"what you need|\"\n",
    "    r\"what we expect|\"\n",
    "    r\"what we['’]re looking for|\"\n",
    "    r\"who you are|\"\n",
    "    r\"what you bring|\"\n",
    "    r\"your profile|\"\n",
    "    r\"about you|\"\n",
    "    r\"ideal candidate|\"\n",
    "    r\"candidate profile|\"\n",
    "    r\"person specification|\"\n",
    "    r\"key attributes|\"\n",
    "    r\"traits we['’]re seeking|\"\n",
    "    r\"essential criteria|\"\n",
    "    r\"selection criteria|\"\n",
    "    r\"minimum qualifications?|\"\n",
    "    r\"preferred qualifications?|\"\n",
    "    r\"desired qualifications?|\"\n",
    "    r\"education and experience|\"\n",
    "    r\"education requirements?|\"\n",
    "    r\"background required\"\n",
    "    r\")\\b\"\n",
    ")\n",
    "\n",
    "\n",
    "req_mask = df[\"job_description\"].str.contains(req_pattern, case=False, na=False)\n",
    "\n",
    "# === Education / Degree / Certification  ===\n",
    "edu_pattern = (\n",
    "    r\"(?i)\\b(\"\n",
    "    r\"education|educational background|\"\n",
    "    r\"degree[s]?|bachelor'?s|master'?s|ph\\.?d|doctorate|mba|major|\"\n",
    "    r\"college degree|university degree|high school diploma|ged|institution|\"\n",
    "    r\"associate'?s degree|advanced degree|graduate degree|undergraduate degree|\"\n",
    "    r\"certification[s]?|certified|license|required license|\"\n",
    "    r\"credential[s]?|training required|academic background|academic requirements\"\n",
    "    r\")\\b\"\n",
    ")\n",
    "edu_mask = df[\"job_description\"].str.contains(edu_pattern, case=False, na=False)\n",
    "\n",
    "total = len(df)\n",
    "both_count = (edu_mask & req_mask).sum()\n",
    "all_three_count = (duties_mask & req_mask & edu_mask).sum()\n",
    "\n",
    "print(f\"Total rows: {total}\")\n",
    "print(f\"Both (Duties+Requirements): {both_count} ({both_count/total:.2%})\")\n",
    "print(f\"All three present: {all_three_count} ({all_three_count/total:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc14f2ff",
   "metadata": {},
   "source": [
    "#### 4.3.2 Section Extraction - Version 4.5 (Keyword-Based)\n",
    "Use keyword pattern matching to extract duties, requirements, and education sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "847beac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# POSITIVE KEYWORDS\n",
    "# ==========================================\n",
    "DUTIES_POS = [\n",
    "    r\"responsibilit\",\n",
    "    r\"duties\",\n",
    "    r\"tasks\",\n",
    "    r\"scope of work\",\n",
    "    r\"deliverables\",\n",
    "    r\"manage\",\n",
    "    r\"support\",\n",
    "    r\"operate\",\n",
    "    r\"coordinate\",\n",
    "    r\"lead\",\n",
    "    r\"overs.*\",\n",
    "    r\"execute\",\n",
    "    r\"perform\",\n",
    "    r\"work closely\",\n",
    "]\n",
    "\n",
    "REQ_POS = [\n",
    "    r\"requirement\",\n",
    "    r\"qualification\",\n",
    "    r\"required\",\n",
    "    r\"preferred\",\n",
    "    r\"skills\",\n",
    "    r\"experience\",\n",
    "    r\"must have\",\n",
    "    r\"ability to\",\n",
    "    r\"proficiency\",\n",
    "    r\"knowledge of\",\n",
    "    r\"strong .* skills\",\n",
    "    r\"familiarity\",\n",
    "    r\"background in\",\n",
    "]\n",
    "\n",
    "EDU_POS = [\n",
    "    r\"bachelor\",\n",
    "    r\"master\",\n",
    "    r\"ph\\.?d\",\n",
    "    r\"degree\",\n",
    "    r\"school\",\n",
    "    r\"diploma\",\n",
    "    r\"ged\",\n",
    "    r\"certification\",\n",
    "    r\"certificate\",\n",
    "    r\"license\",\n",
    "    r\"major in\",\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# NEGATIVE FILTER FOR REQUIREMENT\n",
    "# ==========================================\n",
    "REQ_NEG = [\n",
    "    r\"\\boverview\\b\",\n",
    "    r\"\\babout\\b\",\n",
    "    r\"\\bcompany\\b\",\n",
    "    r\"\\bmission\\b\",\n",
    "    r\"\\bvision\\b\",\n",
    "    r\"\\bvalue\\b\",\n",
    "    r\"\\bwhy join\\b\",\n",
    "    r\"\\bbenefit\\b\",\n",
    "    r\"\\bwho we are\\b\",\n",
    "    r\"\\bwhat we do\\b\",\n",
    "    r\"\\bsummary\\b\",\n",
    "]\n",
    "\n",
    "\n",
    "def is_requirement_sentence(s):\n",
    "    if not match_any(REQ_POS, s):\n",
    "        return False\n",
    "    if match_any(REQ_NEG, s):\n",
    "        return False\n",
    "    # avoid sentences that are too long (like full company descriptions)\n",
    "    if len(s) > 220:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# NEGATIVE FILTER FOR EDUCATION\n",
    "# ==========================================\n",
    "EDU_NEG = [\n",
    "    r\"duties\",\n",
    "    r\"responsibilit\",\n",
    "    r\"tasks\",\n",
    "    r\"construction\",\n",
    "    r\"supervis\",\n",
    "    r\"manage\",\n",
    "    r\"operations\",\n",
    "    r\"project\",\n",
    "    r\"customer\",\n",
    "    r\"service\",\n",
    "    r\"support\",\n",
    "    r\"engineer\",\n",
    "    r\"analysis\",\n",
    "    r\"pipeline\",\n",
    "    r\"maintenance\",\n",
    "]\n",
    "\n",
    "\n",
    "def basic_clean(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", str(text))\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "def split_sentences(text):\n",
    "    return [s.strip() for s in re.split(r\"[\\.!?;\\n]+\", text) if len(s.strip()) > 0]\n",
    "\n",
    "\n",
    "def match_any(patterns, text):\n",
    "    return any(re.search(p, text, re.IGNORECASE) for p in patterns)\n",
    "\n",
    "\n",
    "def no_match(patterns, text):\n",
    "    return not any(re.search(p, text, re.IGNORECASE) for p in patterns)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Strict EDU filter\n",
    "# ==========================================\n",
    "def is_education_sentence(s):\n",
    "\n",
    "    # must contain positive EDU keyword\n",
    "    if not match_any(EDU_POS, s):\n",
    "        return False\n",
    "\n",
    "    # must NOT contain typical duties/req keywords\n",
    "    if match_any(DUTIES_POS, s):\n",
    "        return False\n",
    "    if match_any(REQ_POS, s):\n",
    "        return False\n",
    "\n",
    "    # maximum sentence length\n",
    "    if len(s) > 200:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# CORE extractor\n",
    "# ==========================================\n",
    "def extract_sections_v45(text):\n",
    "    text = basic_clean(text)\n",
    "    sentences = split_sentences(text)\n",
    "\n",
    "    duties, reqs, edu = [], [], []\n",
    "\n",
    "    for s in sentences:\n",
    "\n",
    "        # education first (优先级更高)\n",
    "        if is_education_sentence(s):\n",
    "            edu.append(s)\n",
    "            continue\n",
    "\n",
    "        # requirements\n",
    "        if is_requirement_sentence(s):\n",
    "            reqs.append(s)\n",
    "            continue\n",
    "\n",
    "        # duties\n",
    "        if match_any(DUTIES_POS, s):\n",
    "            duties.append(s)\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"duties\": \"\\n\".join(duties),\n",
    "        \"requirements\": \"\\n\".join(reqs),\n",
    "        \"education\": \"\\n\".join(edu),\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DF WRAPPER\n",
    "# ==========================================\n",
    "def clean_jd_dataframe(df, col=\"job_description\"):\n",
    "    tqdm.pandas(desc=\"Extract JD V4.5 (Better Duties/Req/Edu)\")\n",
    "    result = df[col].progress_apply(extract_sections_v45)\n",
    "\n",
    "    df[\"jd_duties\"] = result.apply(lambda x: x[\"duties\"])\n",
    "    df[\"jd_requirements\"] = result.apply(lambda x: x[\"requirements\"])\n",
    "    df[\"jd_education\"] = result.apply(lambda x: x[\"education\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68161d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract JD V4.5 (Better Duties/Req/Edu): 100%|██████████| 5283/5283 [00:04<00:00, 1252.34it/s]\n"
     ]
    }
   ],
   "source": [
    "df1 = df.copy()\n",
    "\n",
    "df_clean = clean_jd_dataframe(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79355632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813\n"
     ]
    }
   ],
   "source": [
    "cols = [\"jd_duties\", \"jd_requirements\", \"jd_education\"]\n",
    "\n",
    "df_filtered = df_clean[df_clean[cols].apply(lambda x: x.str.len() >= 5).all(axis=1)]\n",
    "print(len(df_filtered))\n",
    "df_filtered[cols].head(5)\n",
    "df_filtered[cols].to_excel(\"filtered_jd_sections1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f36383",
   "metadata": {},
   "source": [
    "#### 4.3.3 Section Extraction - Version 8.4 (SBERT + Hybrid Rules)\n",
    "Use semantic similarity with SBERT embeddings combined with keyword rules for improved extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a8d2e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load SBERT model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Semantic prototypes\n",
    "DUTIES_PROTOTYPE = \"responsibilities, duties, tasks the employee will perform\"\n",
    "REQ_PROTOTYPE = (\n",
    "    \"required skills, qualifications, licenses, certifications, work experience\"\n",
    ")\n",
    "EDU_PROTOTYPE = \"educational requirements, degree in, bachelors, masters, phd, diploma\"\n",
    "\n",
    "proto_embs = model.encode(\n",
    "    [DUTIES_PROTOTYPE, REQ_PROTOTYPE, EDU_PROTOTYPE], convert_to_tensor=True\n",
    ")\n",
    "duties_proto, req_proto, edu_proto = proto_embs\n",
    "\n",
    "\n",
    "# 2. Utility functions\n",
    "\n",
    "\n",
    "def basic_clean(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def split_sentences(text):\n",
    "    # Fix broken lines e.g. “Bachelor’s degree (B”\n",
    "    text = text.replace(\"B .\", \"B.\")\n",
    "    text = re.sub(r\"(?<=\\bB)\\s(?=[A-Z])\", \"\", text)\n",
    "\n",
    "    # sentence split\n",
    "    sents = re.split(r\"[\\.!?;\\n]+\", text)\n",
    "    return [s.strip() for s in sents if len(s.strip()) > 2]\n",
    "\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return float(util.cos_sim(a, b).cpu().numpy())\n",
    "\n",
    "\n",
    "def match_any(patterns, s):\n",
    "    return any(re.search(p, s, re.IGNORECASE) for p in patterns)\n",
    "\n",
    "\n",
    "def no_match(patterns, s):\n",
    "    return not match_any(patterns, s)\n",
    "\n",
    "\n",
    "# 3. Keyword dictionaries\n",
    "\n",
    "# Strong education expressions (very strict)\n",
    "EDU_STRONG = [\n",
    "    r\"bachelor.?s?\\s+degree\",\n",
    "    r\"bachelor\\s+degree\",  # Bachelor's degree / Bachelor degree\n",
    "    r\"master.?s?\\s+degree\",  # Master's degree\n",
    "    r\"High school\" r\"ph\\.?d\",\n",
    "    r\"doctorate\",  # PhD / Doctorate\n",
    "    r\"degree in\",\n",
    "    r\"major in\",  # degree in X / major in X\n",
    "    r\"\\bbs\\b\",\n",
    "    r\"\\bba\\b\",\n",
    "    r\"\\bms\\b\",\n",
    "    r\"\\bma\\b\",  # BS / BA / MS / MA （\n",
    "    r\"b\\.s\\.\",\n",
    "    r\"b\\.a\\.\",\n",
    "    r\"m\\.s\\.\",\n",
    "    r\"m\\.a\\.\",\n",
    "    r\"graduate (student|level|program)\",  # graduate-level / graduate student\n",
    "]\n",
    "\n",
    "\n",
    "# Basic degree keywords (weak)\n",
    "EDU_CORE = [r\"bachelor\", r\"master\", r\"ph\\.?d\", r\"degree\", r\"diploma\", r\"ged\"]\n",
    "\n",
    "# Requirements keywords\n",
    "REQ_POS = [\n",
    "    r\"requirement\",\n",
    "    r\"qualification\",\n",
    "    r\"required\",\n",
    "    r\"skills\",\n",
    "    r\"experience\",\n",
    "    r\"proficiency\",\n",
    "    r\"license\",\n",
    "    r\"licensure\",\n",
    "    r\"certification\",\n",
    "    r\"certified\",\n",
    "    r\"ms office\",\n",
    "    r\"excel\",\n",
    "    r\"powerpoint\",\n",
    "    r\"word\",\n",
    "    r\"outlook\",\n",
    "]\n",
    "\n",
    "# Duties keywords\n",
    "DUTIES_POS = [\n",
    "    r\"responsibilit\",\n",
    "    r\"duties\",\n",
    "    r\"tasks\",\n",
    "    r\"deliverables\",\n",
    "    r\"manage\",\n",
    "    r\"support\",\n",
    "    r\"coordinate\",\n",
    "    r\"lead\",\n",
    "    r\"execute\",\n",
    "]\n",
    "\n",
    "# Company overview blocks (should NEVER be duties or requirements)\n",
    "COMPANY_NEG = [\n",
    "    r\"company information\",\n",
    "    r\"atos is\",\n",
    "    r\"leader in\",\n",
    "    r\"annual revenue\",\n",
    "    r\"employees in\",\n",
    "    r\"global\",\n",
    "    r\"worldwide\",\n",
    "    r\"training programs\",\n",
    "    r\"olympic\",\n",
    "    r\"paralympic\",\n",
    "    r\"eeo\",\n",
    "    r\"equal opportunity\",\n",
    "    r\"our mission\",\n",
    "    r\"our values\",\n",
    "    r\"company culture\",\n",
    "    r\"www\\.\",\n",
    "    r\"company website\",\n",
    "    r\"vision\",\n",
    "    r\"brand\",\n",
    "]\n",
    "\n",
    "# Duties negative filters\n",
    "DUTIES_NEG = COMPANY_NEG + [\n",
    "    r\"benefit\",\n",
    "    r\"salary\",\n",
    "    r\"compensation\",\n",
    "    r\"401k\",\n",
    "    r\"health\",\n",
    "    r\"dental\",\n",
    "    r\"insurance\",\n",
    "    r\"pto\",\n",
    "    r\"vacation\",\n",
    "    r\"training program\",\n",
    "    r\"development program\",\n",
    "]\n",
    "\n",
    "# Requirements negative filters\n",
    "REQ_NEG = COMPANY_NEG + [\n",
    "    r\"benefit\",\n",
    "    r\"compensation\",\n",
    "    r\"bonus\",\n",
    "    r\"401k\",\n",
    "    r\"pto\",\n",
    "    r\"insurance\",\n",
    "    r\"vacation\",\n",
    "    r\"training program\",\n",
    "    r\"career\",\n",
    "    r\"growth\",\n",
    "    r\"promotion\",\n",
    "]\n",
    "\n",
    "# Education negative filters\n",
    "EDU_NEG = COMPANY_NEG + [\n",
    "    r\"benefit\",\n",
    "    r\"salary\",\n",
    "    r\"insurance\",\n",
    "    r\"pto\",\n",
    "    r\"vacation\",\n",
    "    r\"responsibilit\",\n",
    "    r\"duties\",\n",
    "    r\"tasks\",\n",
    "    r\"operations\",\n",
    "    r\"project\",\n",
    "    r\"manage\",\n",
    "    r\"customer\",\n",
    "    r\"ms office\",\n",
    "    r\"excel\",\n",
    "    r\"powerpoint\",\n",
    "    r\"word\",\n",
    "    r\"outlook\",\n",
    "]\n",
    "\n",
    "\n",
    "# 4. Sentence classifier\n",
    "def classify_sentence(s, emb):\n",
    "    duty_sim = cosine_sim(emb, duties_proto)\n",
    "    req_sim = cosine_sim(emb, req_proto)\n",
    "    edu_sim = cosine_sim(emb, edu_proto)\n",
    "\n",
    "    # ----------- Education (Strong FIRST) -----------\n",
    "    if match_any(EDU_STRONG, s) and no_match(EDU_NEG, s):\n",
    "        return \"edu\"\n",
    "\n",
    "    # ----------- Education (Weak → downgrade to requirements) -----------\n",
    "    if match_any(EDU_CORE, s) and no_match(EDU_NEG, s):\n",
    "        # If weak degree match and sentence also contains requirements stuff → requirements\n",
    "        if match_any(REQ_POS, s):\n",
    "            return \"requirements\"\n",
    "        # Else education\n",
    "        return \"edu\"\n",
    "\n",
    "    # ----------- Duties keyword -----------\n",
    "    if match_any(DUTIES_POS, s) and no_match(DUTIES_NEG, s):\n",
    "        return \"duties\"\n",
    "\n",
    "    # ----------- Duties semantic advantage -----------\n",
    "    if duty_sim > req_sim + 0.05:\n",
    "        return \"duties\"\n",
    "\n",
    "    # ----------- Requirements -----------\n",
    "    if (match_any(REQ_POS, s) or req_sim >= 0.38) and no_match(REQ_NEG, s):\n",
    "        return \"requirements\"\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# 5. Extractor\n",
    "def extract_sections_v84(text):\n",
    "    text = basic_clean(text)\n",
    "    sents = split_sentences(text)\n",
    "\n",
    "    if not sents:\n",
    "        return {\"duties\": \"\", \"requirements\": \"\", \"education\": \"\"}\n",
    "\n",
    "    sent_embs = model.encode(sents, convert_to_tensor=True)\n",
    "\n",
    "    duties_s, req_s, edu_s = [], [], []\n",
    "\n",
    "    for i, s in enumerate(sents):\n",
    "        emb = sent_embs[i]\n",
    "        cat = classify_sentence(s, emb)\n",
    "\n",
    "        if cat == \"duties\":\n",
    "            duties_s.append(s)\n",
    "        elif cat == \"requirements\":\n",
    "            req_s.append(s)\n",
    "        elif cat == \"edu\":\n",
    "            edu_s.append(s)\n",
    "\n",
    "    return {\n",
    "        \"duties\": \"\\n\".join(duties_s),\n",
    "        \"requirements\": \"\\n\".join(req_s),\n",
    "        \"education\": \"\\n\".join(edu_s),\n",
    "    }\n",
    "\n",
    "\n",
    "# 6. DataFrame wrapper\n",
    "def clean_jd_dataframe_v84(df, col=\"job_description\"):\n",
    "    tqdm.pandas(desc=\"Extract JD v8.4 (SBERT + Hybrid Rules)\")\n",
    "    result = df[col].progress_apply(extract_sections_v84)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"jd_duties\"] = result.apply(lambda x: x[\"duties\"])\n",
    "    df[\"jd_requirements\"] = result.apply(lambda x: x[\"requirements\"])\n",
    "    df[\"jd_education\"] = result.apply(lambda x: x[\"education\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32379bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract JD v8.4 (SBERT + Hybrid Rules):   0%|          | 0/5283 [00:00<?, ?it/s]/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_76352/1985578339.py:44: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return float(util.cos_sim(a, b).cpu().numpy())\n",
      "Extract JD v8.4 (SBERT + Hybrid Rules): 100%|██████████| 5283/5283 [10:08<00:00,  8.69it/s]\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "df_v8 = clean_jd_dataframe_v84(df2, col=\"job_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d855cbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>location_cleaned</th>\n",
       "      <th>job_title</th>\n",
       "      <th>jd_duties</th>\n",
       "      <th>jd_requirements</th>\n",
       "      <th>jd_education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why Join Altec? If you’re considering a career...</td>\n",
       "      <td>Dixon, CA</td>\n",
       "      <td>Engineer - Quality</td>\n",
       "      <td>Our Company was founded based upon values that...</td>\n",
       "      <td>• EIT registration or ability to obtain regist...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Position ID#  76162 # Positions  1 State  CT C...</td>\n",
       "      <td>Camphill, PA</td>\n",
       "      <td>Shift Supervisor - Part-Time</td>\n",
       "      <td>The primary purpose of this position is to pro...</td>\n",
       "      <td>• In accordance with state law, candidates mus...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Job Description Job #:  720298Apex Systems has...</td>\n",
       "      <td>Charlottesville, VA</td>\n",
       "      <td>Construction PM - Charlottesville</td>\n",
       "      <td>This is a long-term rolling contract supportin...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Insituform Technologies, LLC, an Aegion compan...</td>\n",
       "      <td>Chesterfield, MO</td>\n",
       "      <td>Video Data Management /Transportation Technician</td>\n",
       "      <td>Insituform's businesses consist of sewer, drin...</td>\n",
       "      <td>Listed below are representative requirements f...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Junior ProofreaderOur client's in- house creat...</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Junior Proofreader</td>\n",
       "      <td>This person is responsible for checking proofs...</td>\n",
       "      <td>Accuracy, attention to detail, and strong writ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job_description     location_cleaned  \\\n",
       "3   Why Join Altec? If you’re considering a career...            Dixon, CA   \n",
       "4   Position ID#  76162 # Positions  1 State  CT C...         Camphill, PA   \n",
       "5   Job Description Job #:  720298Apex Systems has...  Charlottesville, VA   \n",
       "9   Insituform Technologies, LLC, an Aegion compan...     Chesterfield, MO   \n",
       "12  Junior ProofreaderOur client's in- house creat...           Boston, MA   \n",
       "\n",
       "                                           job_title  \\\n",
       "3                                 Engineer - Quality   \n",
       "4                       Shift Supervisor - Part-Time   \n",
       "5                  Construction PM - Charlottesville   \n",
       "9   Video Data Management /Transportation Technician   \n",
       "12                                Junior Proofreader   \n",
       "\n",
       "                                            jd_duties  \\\n",
       "3   Our Company was founded based upon values that...   \n",
       "4   The primary purpose of this position is to pro...   \n",
       "5   This is a long-term rolling contract supportin...   \n",
       "9   Insituform's businesses consist of sewer, drin...   \n",
       "12  This person is responsible for checking proofs...   \n",
       "\n",
       "                                      jd_requirements jd_education  \n",
       "3   • EIT registration or ability to obtain regist...               \n",
       "4   • In accordance with state law, candidates mus...               \n",
       "5                                                                   \n",
       "9   Listed below are representative requirements f...               \n",
       "12  Accuracy, attention to detail, and strong writ...               "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v8.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88ef80cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231\n"
     ]
    }
   ],
   "source": [
    "cols = [\"jd_duties\", \"jd_requirements\", \"jd_education\"]\n",
    "\n",
    "df_filtered2 = df_v8[df_v8[cols].apply(lambda x: x.str.len() > 5).all(axis=1)]\n",
    "print(len(df_filtered2))\n",
    "df_filtered2[cols].head(5)\n",
    "df_filtered2.to_excel(\"filtered_jd_sections2.xlsx\", index=False)\n",
    "df_filtered2.to_excel(\"../5_checking_accuracy/jobdescription.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bfea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    jd_df[\n",
    "        jd_df[\"job_description\"].str.contains(\n",
    "            \"Extensive hand-on experience with Microsoft Active Directory\", na=False\n",
    "        )\n",
    "    ][\"job_description\"]\n",
    ")\n",
    "print(jd_df.loc[1761, \"job_description\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
