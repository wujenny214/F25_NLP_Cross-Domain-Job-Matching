{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc55f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7188"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "raw_data=pd.read_csv('0_raw_dataset/job_description.csv')\n",
    "print(len(raw_data))\n",
    "\n",
    "df = pd.read_csv('0_raw_dataset/cleaned_jd_location.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549146d",
   "metadata": {},
   "source": [
    "# check noise data & duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58903534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7158\n",
      "Same job description but different companies, locations, etc., after checking: 0\n",
      "Total number of duplicate job_description lines: 1852\n",
      "5306\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"job_description\"] != \"Please apply only if you are qualified.\"]\n",
    "print(len(df))\n",
    "\n",
    "# there are many duplicate value\n",
    "dupes = df[df[\"job_description\"].duplicated(keep=False)]\n",
    "same_rows = dupes.groupby(\"job_description\").filter(\n",
    "    lambda g: g.drop(columns=[\"job_description\"]).nunique().sum() == 0\n",
    ")\n",
    "\n",
    "print(f\"Same job description but different companies, locations, etc., after checking: {len(same_rows)}\")\n",
    "\n",
    "# drop them\n",
    "duplicates = df[\"job_description\"].value_counts()\n",
    "num_duplicate_rows = duplicates[duplicates > 1].sum()\n",
    "print(\"Total number of duplicate job_description lines:\", num_duplicate_rows)\n",
    "# number not too much, drop them\n",
    "df = df[~df[\"job_description\"].duplicated(keep=False)]\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67840be6",
   "metadata": {},
   "source": [
    "# check key features in job description only using keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78d53dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_39126/85526244.py:28: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  duties_mask = df[\"job_description\"].str.contains(duties_pattern, case=False, na=False)\n",
      "/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_39126/85526244.py:69: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  req_mask = df[\"job_description\"].str.contains(req_pattern, case=False, na=False)\n",
      "/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_39126/85526244.py:82: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  edu_mask = df[\"job_description\"].str.contains(edu_pattern, case=False, na=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 5306\n",
      "Duties-related: 3658 (68.94%)\n",
      "Requirements-related: 3896 (73.43%)\n",
      "Education-related: 3882 (73.16%)\n",
      "Both (Duties+Requirements): 3001 (56.56%)\n",
      "All three present: 2549 (48.04%)\n"
     ]
    }
   ],
   "source": [
    "# === Responsibilities / Duties  ===\n",
    "duties_pattern = (\n",
    "    r\"(?i)\\b(\"\n",
    "    r\"responsibilit(?:y|ies)|\"\n",
    "    r\"duties|\"\n",
    "    r\"tasks|\"\n",
    "    r\"key responsibilities|\"\n",
    "    r\"primary responsibilities|\"\n",
    "    r\"main duties|\"\n",
    "    r\"essential duties|\"\n",
    "    r\"job duties|\"\n",
    "    r\"core responsibilities|\"\n",
    "    r\"what you['’]ll do|\"\n",
    "    r\"what you will do|\"\n",
    "    r\"your role|\"\n",
    "    r\"role overview|\"\n",
    "    r\"day[- ]to[- ]day|\"\n",
    "    r\"main responsibilities|\"\n",
    "    r\"responsibilities|\"\n",
    "    r\"key deliverables|\"\n",
    "    r\"accountabilities|\"\n",
    "    r\"scope of work|\"\n",
    "    r\"what this role does\"\n",
    "    r\")\\b\"\n",
    ")\n",
    "\n",
    "\n",
    "duties_mask = df[\"job_description\"].str.contains(duties_pattern, case=False, na=False)\n",
    "\n",
    "\n",
    "# === Requirements / Qualifications ===\n",
    "req_pattern = (\n",
    "    r\"(?i)\\b(\"\n",
    "    r\"requirements?|\"\n",
    "    r\"qualifications?|\"\n",
    "    r\"skills and experience|\"\n",
    "    r\"required skills?|\"\n",
    "    r\"preferred skills?|\"\n",
    "    r\"experience required|\"\n",
    "    r\"experience and education|\"\n",
    "    r\"knowledge, skills|\"\n",
    "    r\"competencies?|\"\n",
    "    r\"core competencies?|\"\n",
    "    r\"what you['’]ll need|\"\n",
    "    r\"what you need|\"\n",
    "    r\"what we expect|\"\n",
    "    r\"what we['’]re looking for|\"\n",
    "    r\"who you are|\"\n",
    "    r\"what you bring|\"\n",
    "    r\"your profile|\"\n",
    "    r\"about you|\"\n",
    "    r\"ideal candidate|\"\n",
    "    r\"candidate profile|\"\n",
    "    r\"person specification|\"\n",
    "    r\"key attributes|\"\n",
    "    r\"traits we['’]re seeking|\"\n",
    "    r\"essential criteria|\"\n",
    "    r\"selection criteria|\"\n",
    "    r\"minimum qualifications?|\"\n",
    "    r\"preferred qualifications?|\"\n",
    "    r\"desired qualifications?|\"\n",
    "    r\"education and experience|\"\n",
    "    r\"education requirements?|\"\n",
    "    r\"background required\"\n",
    "    r\")\\b\"\n",
    ")\n",
    "\n",
    "\n",
    "req_mask = df[\"job_description\"].str.contains(req_pattern, case=False, na=False)\n",
    "\n",
    "# === Education / Degree / Certification  ===\n",
    "edu_pattern = (\n",
    "    r\"(?i)\\b(\"\n",
    "    r\"education|educational background|\"\n",
    "    r\"degree[s]?|bachelor'?s|master'?s|ph\\.?d|doctorate|mba|major|\"\n",
    "    r\"college degree|university degree|high school diploma|ged|institution|\"\n",
    "    r\"associate'?s degree|advanced degree|graduate degree|undergraduate degree|\"\n",
    "    r\"certification[s]?|certified|license|required license|\"\n",
    "    r\"credential[s]?|training required|academic background|academic requirements\"\n",
    "    r\")\\b\"\n",
    ")\n",
    "edu_mask = df[\"job_description\"].str.contains(edu_pattern, case=False, na=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total = len(df)\n",
    "duties_count = duties_mask.sum()\n",
    "req_count = req_mask.sum()\n",
    "edu_count = edu_mask.sum()\n",
    "both_count = (duties_mask & req_mask).sum()\n",
    "all_three_count = (duties_mask & req_mask & edu_mask).sum()\n",
    "\n",
    "print(f\"Total rows: {total}\")\n",
    "print(f\"Duties-related: {duties_count} ({duties_count/total:.2%})\")\n",
    "print(f\"Requirements-related: {req_count} ({req_count/total:.2%})\")\n",
    "print(f\"Education-related: {edu_count} ({edu_count/total:.2%})\")\n",
    "print(f\"Both (Duties+Requirements): {both_count} ({both_count/total:.2%})\")\n",
    "print(f\"All three present: {all_three_count} ({all_three_count/total:.2%})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2036958",
   "metadata": {},
   "source": [
    "# only keep Duties、Requirements、Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac880eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "clean_jd.py\n",
    "-----------\n",
    "Cleans Job Description (JD) text and detects structural sections.\n",
    "\n",
    "Functions:\n",
    "1. Removes HTML tags, whitespace, and formatting noise.\n",
    "2. Removes EEO statements, legal disclaimers, contact info, and job template sections.\n",
    "3. Retains key content such as responsibilities, requirements, and skills.\n",
    "4. Detects presence of key sections (Responsibilities / Requirements / Education).\n",
    "5. Supports batch cleaning for DataFrames and outputs:\n",
    "   - `jd_cleaned`\n",
    "   - section flags: has_duties, has_requirements, has_education\n",
    "   - coverage statistics summary.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# === Basic Cleaning ===\n",
    "def basic_clean(text: str) -> str:\n",
    "    \"\"\"Remove HTML tags, normalize whitespace, and trim.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)   # Remove HTML tags\n",
    "    text = re.sub(r\"\\s+\", \" \", text)       # Collapse multiple spaces\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# === Remove Noise (legal, EEO, contact info, templates) ===\n",
    "def remove_noise_sections(text: str) -> str:\n",
    "    \"\"\"Remove EEO, legal disclaimers, benefits, and template filler text.\"\"\"\n",
    "    noise_patterns = [\n",
    "        r\"(?i)equal opportunity.*\",\n",
    "        r\"(?i)affirmative action.*\",\n",
    "        r\"(?i)we are an equal.*\",\n",
    "        r\"(?i)www\\.[^\\s]+\",\n",
    "        r\"(?i)visit our website.*\",\n",
    "        r\"(?i)apply now.*\",\n",
    "        r\"(?i)please send.*resume.*\",\n",
    "        r\"(?i)drug test.*\",\n",
    "        r\"(?i)disability.*\",\n",
    "        r\"(?i)insurance.*\",\n",
    "        r\"(?i)benefits include.*\",\n",
    "        r\"(?i)401k.*\",\n",
    "        r\"(?i)bonus.*plan.*\",\n",
    "        r\"(?i)salary.*DOE.*\",\n",
    "        r\"(?i)click here.*\",\n",
    "        r\"(?i)privacy policy.*\",\n",
    "        r\"(?i)background check.*\",\n",
    "    ]\n",
    "    for pat in noise_patterns:\n",
    "        text = re.sub(pat, \" \", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "# === Section Detection Patterns ===\n",
    "DUTIES_PATTERN = (\n",
    "    r\"(?i)\\b(\"\n",
    "    r\"responsibilit(?:y|ies)|duties|tasks|\"\n",
    "    r\"key responsibilities|primary responsibilities|main duties|\"\n",
    "    r\"essential duties|job duties|core responsibilities|\"\n",
    "    r\"what you['’]ll do|what you will do|your role|role overview|\"\n",
    "    r\"day[- ]to[- ]day|main responsibilities|key deliverables|\"\n",
    "    r\"accountabilities|scope of work|what this role does\"\n",
    "    r\")\\b\"\n",
    ")\n",
    "\n",
    "REQ_PATTERN = (\n",
    "    r\"(?i)\\b(\"\n",
    "    r\"requirements?|qualifications?|skills and experience|\"\n",
    "    r\"required skills?|preferred skills?|experience required|\"\n",
    "    r\"experience and education|knowledge, skills|competencies?|\"\n",
    "    r\"core competencies?|what you['’]ll need|what you need|\"\n",
    "    r\"what we expect|what we['’]re looking for|who you are|\"\n",
    "    r\"what you bring|your profile|about you|ideal candidate|\"\n",
    "    r\"candidate profile|person specification|key attributes|\"\n",
    "    r\"traits we['’]re seeking|essential criteria|selection criteria|\"\n",
    "    r\"minimum qualifications?|preferred qualifications?|desired qualifications?|\"\n",
    "    r\"education and experience|education requirements?|background required\"\n",
    "    r\")\\b\"\n",
    ")\n",
    "\n",
    "EDU_PATTERN = (\n",
    "    r\"(?i)\\b(\"\n",
    "    r\"education|educational background|degree[s]?|bachelor'?s|master'?s|ph\\.?d|doctorate|\"\n",
    "    r\"mba|major|college degree|university degree|high school diploma|ged|institution|\"\n",
    "    r\"associate'?s degree|advanced degree|graduate degree|undergraduate degree|\"\n",
    "    r\"certification[s]?|certified|license|required license|credential[s]?|\"\n",
    "    r\"training required|academic background|academic requirements\"\n",
    "    r\")\\b\"\n",
    ")\n",
    "\n",
    "\n",
    "# === Extract Relevant Sections (using patterns above) ===\n",
    "def extract_relevant_sections(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract relevant JD sections using extended regex patterns.\n",
    "    Uses DUTIES_PATTERN, REQ_PATTERN, and EDU_PATTERN.\n",
    "    If no sections found, returns the entire text.\n",
    "    \"\"\"\n",
    "    sections = []\n",
    "\n",
    "    # --- Duties / Responsibilities ---\n",
    "    duties_match = re.search(DUTIES_PATTERN + r\"[:\\-\\n\\r]+(.*?)(?=\\b[A-Z][a-z]{2,}\\b[:\\-\\n\\r]|$)\",\n",
    "                             text, flags=re.DOTALL)\n",
    "    if duties_match:\n",
    "        content = re.sub(r\"\\s+\", \" \", duties_match.group(1)).strip()\n",
    "        if len(content) > 50:\n",
    "            sections.append(f\"Duties: {content}\")\n",
    "\n",
    "    # --- Requirements / Qualifications ---\n",
    "    req_match = re.search(REQ_PATTERN + r\"[:\\-\\n\\r]+(.*?)(?=\\b[A-Z][a-z]{2,}\\b[:\\-\\n\\r]|$)\",\n",
    "                          text, flags=re.DOTALL)\n",
    "    if req_match:\n",
    "        content = re.sub(r\"\\s+\", \" \", req_match.group(1)).strip()\n",
    "        if len(content) > 50:\n",
    "            sections.append(f\"Requirements: {content}\")\n",
    "\n",
    "    # --- Education / Degree ---\n",
    "    edu_match = re.search(EDU_PATTERN + r\"[:\\-\\n\\r]+(.*?)(?=\\b[A-Z][a-z]{2,}\\b[:\\-\\n\\r]|$)\",\n",
    "                          text, flags=re.DOTALL)\n",
    "    if edu_match:\n",
    "        content = re.sub(r\"\\s+\", \" \", edu_match.group(1)).strip()\n",
    "        if len(content) > 50:\n",
    "            sections.append(f\"Education: {content}\")\n",
    "\n",
    "    return \" \".join(sections) if sections else text\n",
    "\n",
    "\n",
    "# === Full Cleaning Pipeline for Single JD ===\n",
    "def clean_jd_text(text: str) -> str:\n",
    "    \"\"\"Apply basic, noise removal, and section extraction to one JD.\"\"\"\n",
    "    text = basic_clean(text)\n",
    "    text = remove_noise_sections(text)\n",
    "    text = extract_relevant_sections(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# === DataFrame-Level Cleaning & Section Tagging ===\n",
    "def clean_jd_dataframe(df: pd.DataFrame, source_col: str = \"job_description\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean all job descriptions in a DataFrame and detect JD structure.\n",
    "    Creates:\n",
    "        - `jd_cleaned` (cleaned text)\n",
    "        - `has_duties`, `has_requirements`, `has_education` flags\n",
    "    Prints structure coverage statistics.\n",
    "    \"\"\"\n",
    "    tqdm.pandas(desc=\"Cleaning job descriptions\")\n",
    "    df = df.copy()\n",
    "\n",
    "    # Clean text\n",
    "    df[\"jd_cleaned\"] = df[source_col].progress_apply(clean_jd_text)\n",
    "\n",
    "    # Section detection flags\n",
    "    df[\"has_duties\"] = df[source_col].str.contains(DUTIES_PATTERN, case=False, na=False)\n",
    "    df[\"has_requirements\"] = df[source_col].str.contains(REQ_PATTERN, case=False, na=False)\n",
    "    df[\"has_education\"] = df[source_col].str.contains(EDU_PATTERN, case=False, na=False)\n",
    "    df[\"has_all_three\"] = df[\"has_duties\"] & df[\"has_requirements\"] & df[\"has_education\"]\n",
    "\n",
    "    # === Summary Statistics ===\n",
    "    total = len(df)\n",
    "    duties_count = df[\"has_duties\"].sum()\n",
    "    req_count = df[\"has_requirements\"].sum()\n",
    "    edu_count = df[\"has_education\"].sum()\n",
    "    all_three = df[\"has_all_three\"].sum()\n",
    "\n",
    "    print(f\"\\n=== JD Structure Summary ===\")\n",
    "    print(f\"Total rows: {total}\")\n",
    "    print(f\"Duties-related: {duties_count} ({duties_count/total:.2%})\")\n",
    "    print(f\"Requirements-related: {req_count} ({req_count/total:.2%})\")\n",
    "    print(f\"Education-related: {edu_count} ({edu_count/total:.2%})\")\n",
    "    print(f\"All three present: {all_three} ({all_three/total:.2%})\")\n",
    "\n",
    "    # Optionally filter by text length\n",
    "    # df = df[df[\"jd_cleaned\"].str.len().between(100, 2000)]\n",
    "\n",
    "    return df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1256bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning job descriptions: 100%|██████████| 5306/5306 [00:03<00:00, 1619.84it/s]\n",
      "/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_39126/1466457001.py:159: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_duties\"] = df[source_col].str.contains(DUTIES_PATTERN, case=False, na=False)\n",
      "/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_39126/1466457001.py:160: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_requirements\"] = df[source_col].str.contains(REQ_PATTERN, case=False, na=False)\n",
      "/var/folders/7c/t23ybbrs56z25_14648nh99w0000gn/T/ipykernel_39126/1466457001.py:161: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df[\"has_education\"] = df[source_col].str.contains(EDU_PATTERN, case=False, na=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== JD Structure Summary ===\n",
      "Total rows: 5306\n",
      "Duties-related: 3658 (68.94%)\n",
      "Requirements-related: 3896 (73.43%)\n",
      "Education-related: 3882 (73.16%)\n",
      "All three present: 2549 (48.04%)\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = clean_jd_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80a40522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== job_description Completeness Summary ===\n",
      "Total rows: 5306\n",
      "Non-null (not NaN): 5306 (100.00%)\n",
      "Null (NaN): 0 (0.00%)\n",
      "Empty strings: 0 (0.00%)\n",
      "Valid non-empty job_description: 5306 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# === Count not-null and null in job_description ===\n",
    "total_rows = len(cleaned_df)\n",
    "not_null_count = cleaned_df[\"job_description\"].notna().sum()\n",
    "null_count = cleaned_df[\"job_description\"].isna().sum()\n",
    "\n",
    "empty_string_count = (cleaned_df[\"job_description\"].str.strip() == \"\").sum()\n",
    "valid_count = total_rows - null_count - empty_string_count\n",
    "\n",
    "print(\"=== job_description Completeness Summary ===\")\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Non-null (not NaN): {not_null_count} ({not_null_count/total_rows:.2%})\")\n",
    "print(f\"Null (NaN): {null_count} ({null_count/total_rows:.2%})\")\n",
    "print(f\"Empty strings: {empty_string_count} ({empty_string_count/total_rows:.2%})\")\n",
    "print(f\"Valid non-empty job_description: {valid_count} ({valid_count/total_rows:.2%})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
