{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bcc738",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ade260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Accuracy (Title + Location exact): 0.280\n",
      "Top-3 Accuracy (Title exact only): 0.310\n",
      "Top-3 Accuracy (Title fuzzy >0.8): 0.450\n",
      "✅ Output file saved as: job_match_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# 1. Load ground truth and prediction data\n",
    "truth = pd.read_excel(\"../5_checking_accuracy/ground_true.xlsx\")\n",
    "pred = pd.read_csv(\"../4_model_outputs/baseline_outputs.csv\")\n",
    "\n",
    "# 2. Merge by resume ID\n",
    "merged = truth.merge(pred, left_on=\"resume_id\", right_on=\"resume_index\", how=\"inner\")\n",
    "\n",
    "# 3. Helper function for fuzzy string similarity\n",
    "def similar(a, b, threshold=0.9):\n",
    "    return SequenceMatcher(None, a, b).ratio() >= threshold\n",
    "\n",
    "# 4. Matching logic\n",
    "def check_match(row):\n",
    "    # --- Collect all ground truth Top-3 title + location pairs ---\n",
    "    gt_pairs = []\n",
    "    for g in [1, 2, 3]:\n",
    "        tcol = f\"top{g}_match_job_title\"\n",
    "        lcol = f\"top{g}_match_job_location\"\n",
    "        if tcol in row and lcol in row:\n",
    "            gt_title = str(row[tcol]).strip().lower()\n",
    "            gt_loc = str(row[lcol]).strip().lower()\n",
    "            if gt_title != \"\" and gt_title.lower() != \"nan\":\n",
    "                gt_pairs.append((gt_title, gt_loc))\n",
    "\n",
    "    # Initialize matching flags\n",
    "    match_both = 0          # Exact match for title + location\n",
    "    match_title = 0         # Exact match for title only\n",
    "    match_title_fuzzy = 0   # Fuzzy match for title (similarity > threshold)\n",
    "\n",
    "    # Optionally include legacy single ground truth columns if present\n",
    "    if \"match_job_title\" in row and \"match_job_location\" in row:\n",
    "        gt_single_title = str(row[\"match_job_title\"]).strip().lower()\n",
    "        gt_single_loc = str(row[\"match_job_location\"]).strip().lower()\n",
    "        if gt_single_title not in [\"\", \"nan\"]:\n",
    "            gt_pairs.append((gt_single_title, gt_single_loc))\n",
    "\n",
    "    # --- Compare all ground truth Top-3 against all predicted Top-3 ---\n",
    "    for gt_title, gt_loc in gt_pairs:\n",
    "        for k in [1, 2, 3]:\n",
    "            pred_title = str(row[f\"top{k}_job_title\"]).strip().lower()\n",
    "            pred_loc = str(row[f\"top{k}_location_cleaned\"]).strip().lower()\n",
    "\n",
    "            # Exact title match\n",
    "            if gt_title == pred_title:\n",
    "                match_title = 1\n",
    "\n",
    "            # Exact title + location match\n",
    "            if gt_title == pred_title and gt_loc == pred_loc:\n",
    "                match_both = 1\n",
    "\n",
    "            # Fuzzy title match (similarity > 0.8)\n",
    "            if similar(gt_title, pred_title, threshold=0.8):\n",
    "                match_title_fuzzy = 1\n",
    "\n",
    "    return pd.Series([match_both, match_title, match_title_fuzzy])\n",
    "\n",
    "# 5. Apply matching function to each row\n",
    "merged[[\"match_flag_both\", \"match_flag_title\", \"match_flag_title_fuzzy\"]] = merged.apply(check_match, axis=1)\n",
    "\n",
    "# 6. Select relevant output columns\n",
    "output_cols = [\n",
    "    \"resume_id\",\n",
    "    # Ground truth Top-3\n",
    "    \"top1_match_job_title\", \"top1_match_job_location\",\n",
    "    \"top2_match_job_title\", \"top2_match_job_location\",\n",
    "    \"top3_match_job_title\", \"top3_match_job_location\",\n",
    "    # Predicted Top-3\n",
    "    \"top1_job_title\", \"top1_location_cleaned\",\n",
    "    \"top2_job_title\", \"top2_location_cleaned\",\n",
    "    \"top3_job_title\", \"top3_location_cleaned\",\n",
    "    # Matching flags\n",
    "    \"match_flag_both\", \"match_flag_title\", \"match_flag_title_fuzzy\",\n",
    "]\n",
    "\n",
    "result = merged[output_cols].copy()\n",
    "\n",
    "# 7. Compute accuracy metrics\n",
    "acc_both = result[\"match_flag_both\"].mean()\n",
    "acc_title = result[\"match_flag_title\"].mean()\n",
    "acc_title_fuzzy = result[\"match_flag_title_fuzzy\"].mean()\n",
    "\n",
    "print(f\"Top-3 Accuracy (Title + Location exact): {acc_both:.3f}\")\n",
    "print(f\"Top-3 Accuracy (Title exact only): {acc_title:.3f}\")\n",
    "print(f\"Top-3 Accuracy (Title fuzzy >0.8): {acc_title_fuzzy:.3f}\")\n",
    "\n",
    "# 8. Save results to CSV\n",
    "result.to_csv(\"job_match_results.csv\", index=False)\n",
    "print(\"✅ Output file saved as: job_match_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c03ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from difflib import SequenceMatcher\n",
    "\n",
    "# # 1. Load data\n",
    "# truth = pd.read_excel(\"../5_checking_accuracy/ground_true.xlsx\")  # Columns: match_job_title, match_job_location\n",
    "# pred = pd.read_csv(\"../4_model_outputs/baseline_outputs.csv\")\n",
    "\n",
    "# # 2. Merge by resume ID\n",
    "# merged = truth.merge(pred, left_on=\"resume_id\", right_on=\"resume_index\", how=\"inner\")\n",
    "\n",
    "# # 3. Helper: fuzzy similarity\n",
    "# def similar(a, b, threshold=0.9):\n",
    "#     return SequenceMatcher(None, a, b).ratio() >= threshold\n",
    "\n",
    "# # 4. Matching logic\n",
    "# def check_match(row):\n",
    "#     gt_title = str(row[\"match_job_title\"]).strip().lower()\n",
    "#     gt_loc = str(row[\"match_job_location\"]).strip().lower()\n",
    "\n",
    "#     match_both = 0\n",
    "#     match_title = 0\n",
    "#     match_title_fuzzy = 0\n",
    "\n",
    "#     for k in [1, 2, 3]:\n",
    "#         pred_title = str(row[f\"top{k}_job_title\"]).strip().lower()\n",
    "#         pred_loc = str(row[f\"top{k}_location_cleaned\"]).strip().lower()\n",
    "\n",
    "#         # exact title\n",
    "#         if gt_title == pred_title:\n",
    "#             match_title = 1\n",
    "#         # title + location\n",
    "#         if gt_title == pred_title and gt_loc == pred_loc:\n",
    "#             match_both = 1\n",
    "#         # fuzzy title\n",
    "#         if similar(gt_title, pred_title, threshold=0.8):\n",
    "#             match_title_fuzzy = 1\n",
    "\n",
    "#     return pd.Series([match_both, match_title, match_title_fuzzy])\n",
    "\n",
    "# # 5. Apply to each row\n",
    "# merged[[\"match_flag_both\", \"match_flag_title\", \"match_flag_title_fuzzy\"]] = merged.apply(check_match, axis=1)\n",
    "\n",
    "# # 6. Select output columns\n",
    "# output_cols = [\n",
    "#     \"resume_id\",\n",
    "#     \"match_job_title\", \"match_job_location\",\n",
    "#     \"top1_job_title\", \"top1_location_cleaned\",\n",
    "#     \"top2_job_title\", \"top2_location_cleaned\",\n",
    "#     \"top3_job_title\", \"top3_location_cleaned\",\n",
    "#     \"match_flag_both\", \"match_flag_title\", \"match_flag_title_fuzzy\",\n",
    "# ]\n",
    "\n",
    "# result = merged[output_cols].copy()\n",
    "\n",
    "# # 7. Compute accuracies\n",
    "# acc_both = result[\"match_flag_both\"].mean()\n",
    "# acc_title = result[\"match_flag_title\"].mean()\n",
    "# acc_title_fuzzy = result[\"match_flag_title_fuzzy\"].mean()\n",
    "\n",
    "# print(f\"Top-3 Accuracy (Title + Location exact): {acc_both:.3f}\")\n",
    "# print(f\"Top-3 Accuracy (Title exact only): {acc_title:.3f}\")\n",
    "# print(f\"Top-3 Accuracy (Title fuzzy >0.8): {acc_title_fuzzy:.3f}\")\n",
    "\n",
    "# # 8. Save results\n",
    "# result.to_csv(\"job_match_results.csv\", index=False)\n",
    "# print(\"✅ Output file saved as: job_match_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd40782",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e8afe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Accuracy (Title + Location exact): 0.190\n",
      "Top-3 Accuracy (Title exact only): 0.250\n",
      "Top-3 Accuracy (Title fuzzy >0.8): 0.500\n",
      "✅ Output file saved as: job_match_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# 1. Load ground truth and prediction data\n",
    "truth = pd.read_excel(\"../5_checking_accuracy/ground_true.xlsx\")  # Columns: match_job_title, match_job_location\n",
    "pred = pd.read_csv(\"../4_model_outputs/crossencoder_outputs.csv\")\n",
    "\n",
    "# 2. Merge by resume ID\n",
    "merged = truth.merge(pred, left_on=\"resume_id\", right_on=\"resume_index\", how=\"inner\")\n",
    "\n",
    "# 3. Helper function for fuzzy string similarity\n",
    "def similar(a, b, threshold=0.9):\n",
    "    return SequenceMatcher(None, a, b).ratio() >= threshold\n",
    "\n",
    "# 4. Matching logic\n",
    "def check_match(row):\n",
    "    # --- Collect all ground truth Top-3 title + location pairs ---\n",
    "    gt_pairs = []\n",
    "    for g in [1, 2, 3]:\n",
    "        tcol = f\"top{g}_match_job_title\"\n",
    "        lcol = f\"top{g}_match_job_location\"\n",
    "        if tcol in row and lcol in row:\n",
    "            gt_title = str(row[tcol]).strip().lower()\n",
    "            gt_loc = str(row[lcol]).strip().lower()\n",
    "            if gt_title != \"\" and gt_title.lower() != \"nan\":\n",
    "                gt_pairs.append((gt_title, gt_loc))\n",
    "\n",
    "    # Initialize matching flags\n",
    "    match_both = 0          # Exact match for title + location\n",
    "    match_title = 0         # Exact match for title only\n",
    "    match_title_fuzzy = 0   # Fuzzy match for title (similarity > threshold)\n",
    "\n",
    "    # Optionally include legacy single ground truth columns if present\n",
    "    if \"match_job_title\" in row and \"match_job_location\" in row:\n",
    "        gt_single_title = str(row[\"match_job_title\"]).strip().lower()\n",
    "        gt_single_loc = str(row[\"match_job_location\"]).strip().lower()\n",
    "        if gt_single_title not in [\"\", \"nan\"]:\n",
    "            gt_pairs.append((gt_single_title, gt_single_loc))\n",
    "\n",
    "    # --- Compare all ground truth Top-3 against all predicted Top-3 ---\n",
    "    for gt_title, gt_loc in gt_pairs:\n",
    "        for k in [1, 2, 3]:\n",
    "            pred_title = str(row[f\"top{k}_job_title\"]).strip().lower()\n",
    "            pred_loc = str(row[f\"top{k}_location_cleaned\"]).strip().lower()\n",
    "\n",
    "            # Exact title match\n",
    "            if gt_title == pred_title:\n",
    "                match_title = 1\n",
    "\n",
    "            # Exact title + location match\n",
    "            if gt_title == pred_title and gt_loc == pred_loc:\n",
    "                match_both = 1\n",
    "\n",
    "            # Fuzzy title match (similarity > 0.8)\n",
    "            if similar(gt_title, pred_title, threshold=0.8):\n",
    "                match_title_fuzzy = 1\n",
    "\n",
    "    return pd.Series([match_both, match_title, match_title_fuzzy])\n",
    "\n",
    "# 5. Apply matching function to each row\n",
    "merged[[\"match_flag_both\", \"match_flag_title\", \"match_flag_title_fuzzy\"]] = merged.apply(check_match, axis=1)\n",
    "\n",
    "# 6. Select relevant output columns\n",
    "output_cols = [\n",
    "    \"resume_id\",\n",
    "    # Ground truth Top-3\n",
    "    \"top1_match_job_title\", \"top1_match_job_location\",\n",
    "    \"top2_match_job_title\", \"top2_match_job_location\",\n",
    "    \"top3_match_job_title\", \"top3_match_job_location\",\n",
    "    # Predicted Top-3\n",
    "    \"top1_job_title\", \"top1_location_cleaned\",\n",
    "    \"top2_job_title\", \"top2_location_cleaned\",\n",
    "    \"top3_job_title\", \"top3_location_cleaned\",\n",
    "    # Matching flags\n",
    "    \"match_flag_both\", \"match_flag_title\", \"match_flag_title_fuzzy\",\n",
    "]\n",
    "\n",
    "result = merged[output_cols].copy()\n",
    "\n",
    "# 7. Compute accuracy metrics\n",
    "acc_both = result[\"match_flag_both\"].mean()\n",
    "acc_title = result[\"match_flag_title\"].mean()\n",
    "acc_title_fuzzy = result[\"match_flag_title_fuzzy\"].mean()\n",
    "\n",
    "print(f\"Top-3 Accuracy (Title + Location exact): {acc_both:.3f}\")\n",
    "print(f\"Top-3 Accuracy (Title exact only): {acc_title:.3f}\")\n",
    "print(f\"Top-3 Accuracy (Title fuzzy >0.8): {acc_title_fuzzy:.3f}\")\n",
    "\n",
    "# 8. Save results to CSV\n",
    "result.to_csv(\"job_match_results.csv\", index=False)\n",
    "print(\"✅ Output file saved as: job_match_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de24ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from difflib import SequenceMatcher\n",
    "\n",
    "# # 1. Load data\n",
    "# truth = pd.read_excel(\"../5_checking_accuracy/ground_true.xlsx\")  # Columns: match_job_title, match_job_location\n",
    "# pred = pd.read_csv(\"../4_model_outputs/crossencoder_outputs.csv\")\n",
    "\n",
    "# # 2. Merge by resume ID\n",
    "# merged = truth.merge(pred, left_on=\"resume_id\", right_on=\"resume_index\", how=\"inner\")\n",
    "\n",
    "# # 3. Helper: fuzzy similarity\n",
    "# def similar(a, b, threshold=0.9):\n",
    "#     return SequenceMatcher(None, a, b).ratio() >= threshold\n",
    "\n",
    "# # 4. Matching logic\n",
    "# def check_match(row):\n",
    "#     gt_title = str(row[\"match_job_title\"]).strip().lower()\n",
    "#     gt_loc = str(row[\"match_job_location\"]).strip().lower()\n",
    "\n",
    "#     match_both = 0\n",
    "#     match_title = 0\n",
    "#     match_title_fuzzy = 0\n",
    "\n",
    "#     for k in [1, 2, 3]:\n",
    "#         pred_title = str(row[f\"top{k}_job_title\"]).strip().lower()\n",
    "#         pred_loc = str(row[f\"top{k}_location_cleaned\"]).strip().lower()\n",
    "\n",
    "#         # exact title\n",
    "#         if gt_title == pred_title:\n",
    "#             match_title = 1\n",
    "#         # title + location\n",
    "#         if gt_title == pred_title and gt_loc == pred_loc:\n",
    "#             match_both = 1\n",
    "#         # fuzzy title\n",
    "#         if similar(gt_title, pred_title, threshold=0.8):\n",
    "#             match_title_fuzzy = 1\n",
    "\n",
    "#     return pd.Series([match_both, match_title, match_title_fuzzy])\n",
    "\n",
    "# # 5. Apply to each row\n",
    "# merged[[\"match_flag_both\", \"match_flag_title\", \"match_flag_title_fuzzy\"]] = merged.apply(check_match, axis=1)\n",
    "\n",
    "# # 6. Select output columns\n",
    "# output_cols = [\n",
    "#     \"resume_id\",\n",
    "#     \"match_job_title\", \"match_job_location\",\n",
    "#     \"top1_job_title\", \"top1_location_cleaned\",\n",
    "#     \"top2_job_title\", \"top2_location_cleaned\",\n",
    "#     \"top3_job_title\", \"top3_location_cleaned\",\n",
    "#     \"match_flag_both\", \"match_flag_title\", \"match_flag_title_fuzzy\",\n",
    "# ]\n",
    "\n",
    "# result = merged[output_cols].copy()\n",
    "\n",
    "# # 7. Compute accuracies\n",
    "# acc_both = result[\"match_flag_both\"].mean()\n",
    "# acc_title = result[\"match_flag_title\"].mean()\n",
    "# acc_title_fuzzy = result[\"match_flag_title_fuzzy\"].mean()\n",
    "\n",
    "# print(f\"Top-3 Accuracy (Title + Location exact): {acc_both:.3f}\")\n",
    "# print(f\"Top-3 Accuracy (Title exact only): {acc_title:.3f}\")\n",
    "# print(f\"Top-3 Accuracy (Title fuzzy >0.8): {acc_title_fuzzy:.3f}\")\n",
    "\n",
    "# # # 8. Save results\n",
    "# # result.to_csv(\"job_match_results.csv\", index=False)\n",
    "# # print(\"Output file saved as: job_match_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3a1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('job_match_results.csv')\n",
    "# df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa65076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 1.Load data\n",
    "# # truth = pd.read_excel(\"../5_checking_accuracy/ground_true.xlsx\")  # Columns: match_job_title, match_job_location\n",
    "# # pred = pd.read_csv(\"../4_model_outputs/baseline_outputs.csv\")\n",
    "\n",
    "# # 2. Merge the two tables on resume ID\n",
    "# merged = truth.merge(pred, left_on=\"resume_id\", right_on=\"resume_index\", how=\"inner\")\n",
    "\n",
    "# # 3. Define matching logic\n",
    "# def check_match(row):\n",
    "#     gt_title = str(row[\"match_job_title\"]).strip().lower()\n",
    "#     gt_loc = str(row[\"match_job_location\"]).strip().lower()\n",
    "\n",
    "#     # Loop through top1–top3 predictions\n",
    "#     for k in [1, 2, 3]:\n",
    "#         pred_title = str(row[f\"top{k}_job_title\"]).strip().lower()\n",
    "#         pred_loc = str(row[f\"top{k}_location_cleaned\"]).strip().lower()\n",
    "#         if gt_title == pred_title and gt_loc == pred_loc:\n",
    "#             return 1  # Match found\n",
    "#     return 0  # No match\n",
    "\n",
    "# # 4. Apply matching function to each row\n",
    "# merged[\"match_flag\"] = merged.apply(check_match, axis=1)\n",
    "\n",
    "# # 5. Select columns for output\n",
    "# output_cols = [\n",
    "#     \"resume_id\",\n",
    "#     \"match_job_title\", \"match_job_location\",\n",
    "#     \"top1_job_title\", \"top1_location_cleaned\",\n",
    "#     \"top2_job_title\", \"top2_location_cleaned\",\n",
    "#     \"top3_job_title\", \"top3_location_cleaned\",\n",
    "#     \"match_flag\",\n",
    "# ]\n",
    "\n",
    "# result2 = merged[output_cols].copy()\n",
    "\n",
    "# # 6. Compute Top-3 Accuracy\n",
    "# top3_acc2 = result2[\"match_flag\"].mean()\n",
    "# print(f\"Top-3 Accuracy (Title + Location match): {top3_acc2:.3f}\")\n",
    "\n",
    "# # 7. Save the results\n",
    "# result2.to_csv(\"job_match_results2.csv\", index=False)\n",
    "# print(\"Output file saved as: job_match_results2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b5aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# # =====================================================\n",
    "# # Metric Functions\n",
    "# # =====================================================\n",
    "# def topk_accuracy(y_true, y_pred_topk, k=3):\n",
    "#     \"\"\"\n",
    "#     Compute Top-k Accuracy and return hit flags.\n",
    "#     \"\"\"\n",
    "#     hits = np.array([y_true[i] in y_pred_topk[i, :k] for i in range(len(y_true))])\n",
    "#     return hits.mean(), hits\n",
    "\n",
    "\n",
    "# def mrr_at_k(y_true, y_pred_topk, k=3):\n",
    "#     \"\"\"\n",
    "#     Compute Mean Reciprocal Rank at K.\n",
    "#     \"\"\"\n",
    "#     scores = []\n",
    "#     for gt, preds in zip(y_true, y_pred_topk):\n",
    "#         if gt in preds[:k]:\n",
    "#             rank = list(preds[:k]).index(gt) + 1\n",
    "#             scores.append(1.0 / rank)\n",
    "#         else:\n",
    "#             scores.append(0.0)\n",
    "#     return np.mean(scores)\n",
    "\n",
    "\n",
    "# def mean_cosine_similarity(y_true, y_pred_top3, resume_embs, job_embs, hits):\n",
    "#     \"\"\"\n",
    "#     Compute Mean Cosine Similarity between resume embeddings and\n",
    "#     ground-truth / predicted job embeddings.\n",
    "#     \"\"\"\n",
    "#     true_sims, miss_sims = [], []\n",
    "\n",
    "#     for i, gt in enumerate(y_true):\n",
    "#         try:\n",
    "#             # Retrieve embeddings\n",
    "#             r_emb = resume_embs[i]\n",
    "#             gt_emb = job_embs[gt]\n",
    "#         except KeyError:\n",
    "#             continue  # Skip if embedding not found\n",
    "\n",
    "#         # Cosine similarity between resume and ground-truth job\n",
    "#         true_sim = cosine_similarity(r_emb.reshape(1, -1), gt_emb.reshape(1, -1))[0, 0]\n",
    "#         true_sims.append(true_sim)\n",
    "\n",
    "#         # Cosine similarity between ground-truth job and top-3 predicted jobs\n",
    "#         pred_embs = np.array([job_embs[j] for j in y_pred_top3[i] if j in job_embs])\n",
    "#         if len(pred_embs) > 0:\n",
    "#             sims = cosine_similarity(gt_emb.reshape(1, -1), pred_embs)[0]\n",
    "#             best_sim = sims.max()\n",
    "#             if not hits[i]:\n",
    "#                 miss_sims.append(best_sim)\n",
    "\n",
    "#     mean_all = np.mean(true_sims)\n",
    "#     mean_miss = np.mean(miss_sims) if len(miss_sims) > 0 else None\n",
    "#     return mean_all, mean_miss\n",
    "\n",
    "\n",
    "# # =====================================================\n",
    "# # Main Evaluation Function\n",
    "# # =====================================================\n",
    "# def evaluate_model_output(\n",
    "#     ground_truth_path,\n",
    "#     model_output_path,\n",
    "#     resume_embs,\n",
    "#     job_embs,\n",
    "#     col_map=None,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Evaluate Top-3 Accuracy, MRR@3, and Mean Cosine Similarity.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     ground_truth_path : str\n",
    "#         Path to the ground-truth CSV file (must include resume_id and top1_job_id).\n",
    "#     model_output_path : str\n",
    "#         Path to the model output CSV file.\n",
    "#     resume_embs : np.ndarray or dict\n",
    "#         Resume embeddings (either aligned by index or mapped by resume_id).\n",
    "#     job_embs : np.ndarray or dict\n",
    "#         Job embeddings (aligned by job_id or index).\n",
    "#     col_map : dict, optional\n",
    "#         Column name mapping for model output file, e.g.:\n",
    "#         {\n",
    "#             \"resume_id\": \"resume_index\",\n",
    "#             \"top1\": \"top1_jd_index\",\n",
    "#             \"top2\": \"top2_jd_index\",\n",
    "#             \"top3\": \"top3_jd_index\"\n",
    "#         }\n",
    "#     \"\"\"\n",
    "#     # Default column mapping\n",
    "#     default_cols = {\n",
    "#         \"resume_id\": \"resume_index\",\n",
    "#         \"top1\": \"top1_jd_index\",\n",
    "#         \"top2\": \"top2_jd_index\",\n",
    "#         \"top3\": \"top3_jd_index\",\n",
    "#     }\n",
    "#     if col_map is not None:\n",
    "#         default_cols.update(col_map)\n",
    "\n",
    "#     # Load data\n",
    "#     truth = pd.read_csv(ground_truth_path)\n",
    "#     pred = pd.read_csv(model_output_path)\n",
    "\n",
    "#     # Merge on resume ID\n",
    "#     merged = truth.merge(\n",
    "#         pred, left_on=\"resume_id\", right_on=default_cols[\"resume_id\"]\n",
    "#     )\n",
    "\n",
    "#     # Build arrays\n",
    "#     y_true = merged[\"top1_job_id\"].astype(int).values\n",
    "#     y_pred_top3 = (\n",
    "#         merged[[default_cols[\"top1\"], default_cols[\"top2\"], default_cols[\"top3\"]]]\n",
    "#         .astype(int)\n",
    "#         .values\n",
    "#     )\n",
    "\n",
    "#     # Compute metrics\n",
    "#     top3_acc, hits = topk_accuracy(y_true, y_pred_top3, k=3)\n",
    "#     mrr3 = mrr_at_k(y_true, y_pred_top3, k=3)\n",
    "#     mean_all, mean_miss = mean_cosine_similarity(\n",
    "#         y_true, y_pred_top3, resume_embs, job_embs, hits\n",
    "#     )\n",
    "\n",
    "#     # Print summary\n",
    "#     print(\"======================================\")\n",
    "#     print(f\"Top-3 Accuracy: {top3_acc:.3f}\")\n",
    "#     print(f\"MRR@3: {mrr3:.3f}\")\n",
    "#     print(f\"Mean Cosine Similarity (all): {mean_all:.3f}\")\n",
    "#     if mean_miss is not None:\n",
    "#         print(f\"Mean Cosine Similarity (miss only): {mean_miss:.3f}\")\n",
    "#     print(\"======================================\")\n",
    "\n",
    "#     return {\n",
    "#         \"Top3_Accuracy\": top3_acc,\n",
    "#         \"MRR@3\": mrr3,\n",
    "#         \"MeanCosSim_all\": mean_all,\n",
    "#         \"MeanCosSim_miss\": mean_miss,\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad18539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
